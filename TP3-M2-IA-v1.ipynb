{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage automatique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP N°3 - Apprentissage automatique\n",
    "### Le Perceptron multicouche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Chargement des données de MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertion des bibliothèques\n",
    "import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La version de numpy est : 1.26.4\n"
     ]
    }
   ],
   "source": [
    "print(\"La version de numpy est :\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "\n",
    "mnistData = mnist.MNIST(\"Data\\\\MNIST\") # Path of the four ubyte files.\n",
    "trainData, trainLabels = mnistData.load_training()\n",
    "testData, testLabels = mnistData.load_testing()\n",
    "trainData = np.array(trainData)\n",
    "trainLabels = np.array(trainLabels).reshape(len(trainLabels), 1)\n",
    "testData = np.array(testData)\n",
    "testLabels = np.array(testLabels).reshape(1, len(testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "..............@@@@@@........\n",
      "...........@@@@@@@@@@.......\n",
      "..........@@@@@@@@@@@@......\n",
      "..........@@@.....@@@@......\n",
      "..................@@@.......\n",
      "..................@@@.......\n",
      "..................@@@.......\n",
      "...............@@@@@@.......\n",
      "..............@@@@@.........\n",
      ".........@@@@@@@@@..........\n",
      ".........@@@@@@@@@@.........\n",
      ".................@@.........\n",
      ".................@@.........\n",
      ".................@@.........\n",
      "................@@@.........\n",
      ".......@.......@@@@.........\n",
      ".....@@@.....@@@@...........\n",
      ".....@@@@@@@@@@@............\n",
      ".......@@@@@@@..............\n",
      "........@@..................\n",
      "............................\n",
      "............................\n",
      "............................\n"
     ]
    }
   ],
   "source": [
    "# Visualisation du contenu d’une image \n",
    "\n",
    "print(mnist.MNIST().display(trainData[7])) # I is the index of the image et peut être n'importe quel chifre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat obtenu n'est pas fiable/correcte. Une modification est nécessaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Normalisation des données\n",
    "\n",
    "La méthode d’optimisation liée au Perceptron multicouche (c.-à-d. la descente de gradient),\n",
    "est optimale lorsque les données sont dans un interval particulier Xn ∈ [0, 1]. Ainsi, normalisez\n",
    "les données des bases WDBC et MNIST par leur maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "\n",
    "mnistData = mnist.MNIST(\"Data\\\\MNIST\") # Path of the four ubyte files.\n",
    "trainData, trainLabels = mnistData.load_training()\n",
    "testData, testLabels = mnistData.load_testing()\n",
    "trainData = np.array(trainData)/255 # afin de diviser par des floatant toujours entre 0 et 1\n",
    "trainLabels = np.array(trainLabels).reshape(len(trainLabels), 1)\n",
    "testData = np.array(testData)/255\n",
    "testLabels = np.array(testLabels).reshape(1, len(testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabelsMatrix = np.zeros((trainLabels.size, 10))\n",
    "for n in range(trainLabels.size):\n",
    "    trainLabelsMatrix[n, trainLabels[n]] = 1\n",
    "    \n",
    "# return trainData, trainLabelsMatrix, testData, testLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n"
     ]
    }
   ],
   "source": [
    "# Visualisation du contenu d’une image \n",
    "\n",
    "print(mnist.MNIST().display(trainData[4])) # I is the index of the image et peut être n'importe quel chifre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04705882\n",
      " 0.38823529 0.35686275 0.55686275 0.60784314 0.96470588 0.71372549\n",
      " 0.60784314 0.60784314 0.60784314 0.60784314 0.51372549 0.20392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.54117647 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.98823529 0.82352941 0.47843137\n",
      " 0.12941176 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.8627451  0.99607843 0.99607843 0.99607843 0.92156863\n",
      " 0.74117647 0.74117647 0.74117647 0.74117647 0.58823529 0.74117647\n",
      " 0.80392157 0.99607843 0.99607843 0.99607843 0.29411765 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1372549\n",
      " 0.29019608 0.1372549  0.1372549  0.09803922 0.         0.\n",
      " 0.         0.         0.         0.         0.05098039 0.87843137\n",
      " 0.99607843 0.99607843 0.6        0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.35294118 0.99607843 0.99607843 0.96862745\n",
      " 0.20784314 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.02352941 0.59607843\n",
      " 0.96470588 0.99607843 0.99607843 0.19215686 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.25882353 0.61960784 0.99607843 0.99607843 0.97647059\n",
      " 0.40392157 0.03137255 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.21176471 0.98431373\n",
      " 0.99607843 0.99607843 0.99607843 0.97254902 0.29019608 0.01960784\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.54901961 0.99607843 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.79215686 0.49019608 0.17647059\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.22745098 0.70980392 0.91764706 0.99607843 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.98823529 0.54901961 0.08627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.11764706 0.19607843 0.28627451 0.60784314 0.99215686 0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.74901961 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.35686275 0.78431373 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.4627451  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.01568627 0.75294118 0.99607843 0.99607843 0.99607843\n",
      " 0.60392157 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.55294118 0.99607843 0.99607843 0.99607843 0.45490196 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09803922 0.49411765 0.3372549  0.         0.         0.\n",
      " 0.         0.         0.         0.01176471 0.7372549  0.99607843\n",
      " 0.99607843 0.98039216 0.23921569 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.09411765 0.81960784 0.99607843\n",
      " 0.05882353 0.         0.         0.         0.         0.\n",
      " 0.09019608 0.5372549  0.99607843 0.99607843 0.99607843 0.81960784\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.65882353 0.99607843 0.99607843 0.18823529 0.03529412\n",
      " 0.         0.         0.03529412 0.49803922 0.94509804 0.99607843\n",
      " 0.99607843 1.         0.94901961 0.24705882 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.39607843\n",
      " 0.99607843 0.99607843 0.99607843 0.80392157 0.74509804 0.74509804\n",
      " 0.80392157 0.99607843 0.99607843 0.99607843 0.99607843 0.94901961\n",
      " 0.2627451  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.12941176 0.65098039 0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843\n",
      " 0.99607843 0.98039216 0.54117647 0.21568627 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.02745098 0.34509804 0.60392157 0.45490196\n",
      " 0.76078431 0.76078431 0.60392157 0.60392157 0.34509804 0.19215686\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "def readMnist(mnistPath) : \n",
    "    mnistData = mnist.MNIST(mnistPath) # Path of the four ubyte files.\n",
    "    trainData, trainLabels = mnistData.load_training()\n",
    "    testData, testLabels = mnistData.load_testing()\n",
    "    trainData = np.array(trainData)/255 # afin de diviser par des floatant toujours entre 0 et 1\n",
    "    trainLabels = np.array(trainLabels).reshape(len(trainLabels), 1)\n",
    "    testData = np.array(testData)/255\n",
    "    testLabels = np.array(testLabels).reshape(1, len(testLabels))\n",
    "    trainLabelsMatrix = np.zeros((trainLabels.size, 10))\n",
    "    for n in range(trainLabels.size):\n",
    "        trainLabelsMatrix[n, trainLabels[n]] = 1\n",
    "        \n",
    "    return trainData, trainLabelsMatrix, testData, testLabels\n",
    "\n",
    "trainData, trainLabels, testData, testLabels = readMnist(\"Data\\\\MNIST\")\n",
    "print(trainData[12, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Fonction d’activation\n",
    "\n",
    "Afin que le réseau de neurones apprenne, il est nécessaire de définir une fonction d’activation.\n",
    "Dans notre cas, nous utiliserons la fonction sigmoïde, voir équation 1 ainsi que sa dérivée pour\n",
    "l’étape de back-propagation, voir équation 2. Où derivate vaut False si on souhaite calculer f(x) et True si on souhaite calculer f′(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, derivate=False):\n",
    "    fx = 1/(1+ np.exp(-x))\n",
    "    if derivate:\n",
    "        return fx*(1 - fx)\n",
    "    return fx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Apprentissage du réseau de neurones\n",
    "\n",
    "Dans cette partie, on souhaite définir le réseau de neurones et l’entraîner sur les données d’entraînement. Pour un meilleur apprentissage, nous utiliserons la technique du batch-processing.\n",
    "\n",
    "Notre réseau de neurones sera défini comme suit :\n",
    "\n",
    "• Nombre de neurones d’entrées : 3 pour WDBC - 28 ∗ 28 = 784 pour MNIST.\n",
    "\n",
    "• Nombre de couches cachées : 1.\n",
    "\n",
    "• Nombre de neurones dans le niveau caché : 20 pour WDBC - 30 pour MNIST.\n",
    "\n",
    "• Nombre de neurones de sorties : 1 pour WDBC - 10 pour MNIST.\n",
    "\n",
    "\n",
    "Afin de créer ce réseau, définissez la fonction suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNeuralNetwork(input, output, hiddenLayerSize, batchSize, learningRate,numberOfIterations):\n",
    "    \"\"\" Train neural network\"\"\"\n",
    "    inputSize = input.shape[1]\n",
    "    outputSize = output.shape[1]\n",
    "    errors = np.zeros(numberOfIterations)\n",
    "    \n",
    "    # Initialisation des poids\n",
    "    weigths0 = np.random.rand(inputSize, hiddenLayerSize)/batchSize\n",
    "    weigths1 = np.random.rand(hiddenLayerSize, outputSize)/batchSize\n",
    "    \n",
    "    # Algorithme\n",
    "    for i in range(numberOfIterations):\n",
    "        # Calcul de la sortie de chaque couche \n",
    "        # Y l = f(qN i=1 WilXil)\n",
    "        layer0 = input\n",
    "        layer1 = sigmoid(layer0.dot(weigths0))\n",
    "        layer2 = sigmoid(layer1.dot(weigths1))\n",
    "        \n",
    "        \n",
    "        # Calcul de l’erreur d’apprentissage El\n",
    "        layer2Error = output - layer2\n",
    "        errors[i] = np.mean(np.sum(abs(layer2Error),1))\n",
    "        \n",
    "        # Rétropropagation de l’erreur par descente de gradient\n",
    "        layer2Delta = layer2Error*sigmoid(layer1.dot(weigths1),True)\n",
    "        layer1Error = layer2Delta.dot(weigths1.transpose())\n",
    "        layer1Delta = layer1Error*sigmoid(layer0.dot(weigths0),True)\n",
    "        \n",
    "        # Mise à jour des poids Wli\n",
    "        weigths0 += learningRate*layer0.transpose().dot(layer1Delta)\n",
    "        weigths1 += learningRate*layer1.transpose().dot(layer2Delta)\n",
    "    \n",
    "    return weigths0,weigths1,errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_2360\\1238430488.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1+ np.exp(-x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.00829001, 0.00335082, 0.0062793 , ..., 0.00362094, 0.00376986,\n",
       "         0.01993916],\n",
       "        [0.0163058 , 0.01765335, 0.00792565, ..., 0.01844101, 0.00595729,\n",
       "         0.01339285],\n",
       "        [0.0114012 , 0.00415473, 0.01804638, ..., 0.01096212, 0.00405876,\n",
       "         0.01921655],\n",
       "        ...,\n",
       "        [0.01953891, 0.01691806, 0.01407447, ..., 0.01742836, 0.01449745,\n",
       "         0.01696711],\n",
       "        [0.01749593, 0.01357308, 0.0088447 , ..., 0.00885303, 0.01047079,\n",
       "         0.01602733],\n",
       "        [0.01388382, 0.01675935, 0.00564935, ..., 0.01375161, 0.00434355,\n",
       "         0.0162754 ]]),\n",
       " array([[-48189.41639224, -47925.39773891, -48275.98757912,\n",
       "         -48271.49800821, -48721.04099264, -49793.38698457,\n",
       "         -48934.0817977 , -48629.08598685, -48640.96085871,\n",
       "         -48790.60944458],\n",
       "        [-49077.06032568, -48642.86064414, -49189.85833659,\n",
       "         -49161.7551828 , -49594.74333124, -50601.54751763,\n",
       "         -49692.91220927, -49413.37141195, -49452.79890665,\n",
       "         -49629.0480101 ],\n",
       "        [-49131.50459304, -48623.56330305, -49214.98088072,\n",
       "         -49161.107248  , -49481.99456877, -50631.7515642 ,\n",
       "         -49773.37837833, -49442.9852636 , -49414.54381767,\n",
       "         -49516.58432309],\n",
       "        [-49056.85940505, -48911.43926548, -49253.88042567,\n",
       "         -49196.43787721, -49472.49279299, -50633.70595987,\n",
       "         -49783.06372784, -49375.4762473 , -49464.7782986 ,\n",
       "         -49505.51477823],\n",
       "        [-48613.76058372, -48369.71000694, -48712.15967713,\n",
       "         -48697.1649001 , -49102.32137872, -50186.68061465,\n",
       "         -49435.424247  , -49020.2003165 , -49030.90131575,\n",
       "         -49157.80934526],\n",
       "        [-49259.5320342 , -49091.63781244, -49491.56372119,\n",
       "         -49383.96900896, -49817.81352703, -50847.3353589 ,\n",
       "         -50004.54641991, -49785.42309886, -49694.78024793,\n",
       "         -49864.01195803],\n",
       "        [-49478.14946213, -49299.10877589, -49615.04506833,\n",
       "         -49542.31816533, -50017.71742409, -51053.20758059,\n",
       "         -50291.08455383, -49834.54949152, -49838.08638099,\n",
       "         -50093.50880313],\n",
       "        [-48099.94686112, -47835.48089936, -48279.81781646,\n",
       "         -48142.7641873 , -48735.27276915, -49655.0312128 ,\n",
       "         -48881.01942008, -48640.06861369, -48543.99287712,\n",
       "         -48761.51825842],\n",
       "        [-48649.85532583, -48463.4264359 , -48803.60405108,\n",
       "         -48873.24984454, -49206.11290139, -50226.40584249,\n",
       "         -49396.70409204, -49185.23105144, -49149.08455797,\n",
       "         -49278.17944783],\n",
       "        [-48273.58884804, -47928.27520274, -48389.98056765,\n",
       "         -48261.10950413, -48732.54559211, -49745.69581664,\n",
       "         -49037.4898779 , -48648.87757668, -48603.38275332,\n",
       "         -48714.59959823],\n",
       "        [-47883.61358151, -47509.24238553, -48050.6127593 ,\n",
       "         -47957.52381695, -48352.49891277, -49399.3680402 ,\n",
       "         -48620.45765056, -48412.38178956, -48289.62218809,\n",
       "         -48407.70553132],\n",
       "        [-49276.8314405 , -48813.36129766, -49261.17786117,\n",
       "         -49136.021412  , -49551.01995144, -50751.55550841,\n",
       "         -49871.03505874, -49531.2296632 , -49533.71700542,\n",
       "         -49591.44547959],\n",
       "        [-49646.77651467, -49276.78104531, -49763.1513298 ,\n",
       "         -49723.15799151, -50201.54903016, -51219.33534202,\n",
       "         -50413.13999831, -50037.98941953, -50044.92690366,\n",
       "         -50218.80703385],\n",
       "        [-48749.85270521, -48316.00303275, -48779.63407388,\n",
       "         -48703.05061794, -49199.40620341, -50235.09385859,\n",
       "         -49367.3669363 , -49074.45740223, -49117.44145233,\n",
       "         -49160.2609352 ],\n",
       "        [-48494.27748771, -48473.71353765, -48777.92802993,\n",
       "         -48648.31226947, -49150.29331747, -50153.1315928 ,\n",
       "         -49348.49669291, -49031.55044974, -49050.24193795,\n",
       "         -49219.46074951],\n",
       "        [-48899.27978009, -48690.35731084, -49020.9084563 ,\n",
       "         -49042.47835614, -49325.4220728 , -50386.04845505,\n",
       "         -49633.46837456, -49205.28817505, -49263.08792238,\n",
       "         -49407.68406898],\n",
       "        [-49045.76098136, -48760.95949881, -49167.02866362,\n",
       "         -49131.48539496, -49586.07386781, -50659.93736239,\n",
       "         -49872.05817358, -49426.40302247, -49496.8267678 ,\n",
       "         -49568.17543269],\n",
       "        [-48426.0763449 , -48137.65494006, -48571.5727802 ,\n",
       "         -48540.78821712, -48908.72953174, -49963.17338045,\n",
       "         -49122.73767334, -48795.34214935, -48801.65378948,\n",
       "         -48938.46383039],\n",
       "        [-48454.62029447, -48289.32709345, -48660.02036309,\n",
       "         -48555.54547504, -49009.18515803, -50027.17664687,\n",
       "         -49233.00890285, -48936.79895105, -48926.32002517,\n",
       "         -49045.63184422],\n",
       "        [-49042.73221247, -48902.05147311, -49178.97119533,\n",
       "         -49154.21740392, -49455.40586045, -50653.48002272,\n",
       "         -49797.58114626, -49276.88043755, -49424.75571458,\n",
       "         -49456.95154115],\n",
       "        [-48791.25727947, -48521.32537651, -48965.26841562,\n",
       "         -48824.02032505, -49324.12665745, -50336.6882887 ,\n",
       "         -49536.68612169, -49141.73830753, -49168.07376432,\n",
       "         -49301.069946  ],\n",
       "        [-49281.57151157, -48963.19193884, -49425.51961497,\n",
       "         -49460.65987853, -49882.51472362, -50861.61774999,\n",
       "         -50052.59924775, -49775.58576591, -49688.03964179,\n",
       "         -49916.27137075],\n",
       "        [-48780.81229502, -48429.20174103, -48969.28044113,\n",
       "         -48832.28142649, -49274.66669434, -50312.909865  ,\n",
       "         -49599.425156  , -49087.70885028, -49154.44696234,\n",
       "         -49287.60268544],\n",
       "        [-48691.9533485 , -48470.76158716, -48820.5332477 ,\n",
       "         -48714.8711487 , -49219.63953684, -50240.60616576,\n",
       "         -49451.20729999, -49118.6917196 , -49132.16082825,\n",
       "         -49230.85345561],\n",
       "        [-48927.81114261, -48626.34460576, -49071.31090466,\n",
       "         -49019.89077872, -49407.03307815, -50413.69588422,\n",
       "         -49579.99259438, -49299.77316294, -49295.64327439,\n",
       "         -49440.7559555 ],\n",
       "        [-49494.63059203, -49149.23946158, -49633.74163535,\n",
       "         -49530.4297641 , -50025.57586914, -51026.31829674,\n",
       "         -50177.01146498, -49927.82771118, -49841.00630875,\n",
       "         -50040.41468332],\n",
       "        [-49119.57996504, -48908.45521204, -49335.5778774 ,\n",
       "         -49276.36233632, -49619.55245581, -50706.3508019 ,\n",
       "         -49862.3014507 , -49485.11338907, -49595.80974802,\n",
       "         -49661.41783014],\n",
       "        [-48138.20562615, -47989.95127831, -48311.79833146,\n",
       "         -48354.72947779, -48634.59923475, -49727.74742239,\n",
       "         -48898.65963712, -48573.9279442 , -48595.52397723,\n",
       "         -48735.23097896],\n",
       "        [-49051.58979845, -48588.83575915, -49101.57929709,\n",
       "         -49035.35147094, -49424.75765748, -50504.73734697,\n",
       "         -49656.93899376, -49247.26848122, -49391.47363596,\n",
       "         -49458.86010753],\n",
       "        [-48339.62508927, -48052.74921067, -48349.79309349,\n",
       "         -48457.27083854, -48704.98081832, -49911.02212027,\n",
       "         -48986.08874846, -48566.62639434, -48691.97206622,\n",
       "         -48733.15802457]]),\n",
       " array([5.44056982, 5.        , 5.        , 5.        , 5.        ]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData, trainLabels, testData, testLabels = readMnist(\"Data\\\\MNIST\")\n",
    "trainNeuralNetwork(trainData, trainLabels, 30 ,50 , 10,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> overflow ormal car fonction d'apprentissage pas fonctionnel (outofnumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNeuralNetwork(input, output, hiddenLayerSize, batchSize, learningRate,numberOfIterations):\n",
    "    \"\"\" Train neural network\"\"\"\n",
    "    inputSize = input.shape[1]\n",
    "    outputSize = output.shape[1]\n",
    "    errors = np.zeros(numberOfIterations)\n",
    "    \n",
    "    # Initialisation des poids\n",
    "    weigths0 = np.random.rand(inputSize, hiddenLayerSize)/inputSize\n",
    "    weigths1 = np.random.rand(hiddenLayerSize, outputSize)/hiddenLayerSize\n",
    "    \n",
    "    # Algorithme\n",
    "    for i in range(numberOfIterations):\n",
    "        n = np.random.randint(0,input.shape[0] - batchSize +1)\n",
    "        # Calcul de la sortie de chaque couche \n",
    "        # Y l = f(qN i=1 WilXil)\n",
    "        layer0 = input[n:n + batchSize, :]\n",
    "        layer1 = sigmoid(layer0.dot(weigths0))\n",
    "        layer2 = sigmoid(layer1.dot(weigths1))\n",
    "        \n",
    "        \n",
    "        # Calcul de l’erreur d’apprentissage El\n",
    "        layer2Error = output[n:n + batchSize, :] - layer2\n",
    "        errors[i] = np.mean(np.sum(abs(layer2Error),1))\n",
    "        \n",
    "        # Rétropropagation de l’erreur par descente de gradient\n",
    "        layer2Delta = layer2Error*sigmoid(layer1.dot(weigths1),True)\n",
    "        layer1Error = layer2Delta.dot(weigths1.transpose())\n",
    "        layer1Delta = layer1Error*sigmoid(layer0.dot(weigths0),True)\n",
    "        \n",
    "        # Mise à jour des poids Wli\n",
    "        weigths0 += learningRate*layer0.transpose().dot(layer1Delta)/batchSize\n",
    "        weigths1 += learningRate*layer1.transpose().dot(layer2Delta)/batchSize\n",
    "    \n",
    "    return weigths0,weigths1,errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainData, trainLabels, testData, testLabels = readMnist(\"Data\\\\MNIST\")\n",
    "weigths0,weigths1,errors = trainNeuralNetwork(trainData, trainLabels, 30 ,50 , 10,5)\n",
    "plt.plot(errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> plus d'overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyNeuralNetWork(input, weigths0, weigths1):\n",
    "    \"\"\"Apply neurol network\"\"\"\n",
    "    layer0 = input\n",
    "    layer1 = sigmoid(layer0.dot(weigths0))\n",
    "    layer2 = sigmoid(layer1.dot(weigths1))\n",
    "    return layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.17\n"
     ]
    }
   ],
   "source": [
    "trainData, trainLabels, testData, testLabels = readMnist(\"Data\\\\MNIST\")\n",
    "weigths0,weigths1,errors = trainNeuralNetwork(trainData, trainLabels, 30 ,50 , 10,15000)\n",
    "# plt.plot(errors)\n",
    "testLabelsPredicted = applyNeuralNetWork(testData, weigths0, weigths1)\n",
    "# plt.show()\n",
    "testLabelsPredicted = np.argmax(testLabelsPredicted, 1)\n",
    "print(100*np.mean(testLabelsPredicted == testLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut rajouter des valeurs afin d'avoir un résultat cohérent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enseignement_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
